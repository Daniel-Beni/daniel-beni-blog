---
title: "Post-Mortem Cloudflare : Quand un Fichier de Configuration Double de Taille"
description: "Analyse technique de la panne Cloudflare du 18 novembre 2025 causÃ©e par un changement de permissions ClickHouse - LeÃ§ons sur la rÃ©silience des systÃ¨mes distribuÃ©s"
date: "2024-11-27"
lastModified: "2024-11-27"
author: "Daniel Beni Niyobuzima"
category: "cloud"
tags: ["cloudflare", "clickhouse", "incident", "post-mortem", "bot-management"]
difficulty: "intermediate"
language: "fr"
published: true
featured: true
---

# Post-Mortem Cloudflare : Quand un Fichier de Configuration Double de Taille

Le 18 novembre 2025, Cloudflare a connu sa pire panne depuis 2019, affectant les services CDN, WAF, Workers et Access pendant prÃ¨s de 6 heures. Contrairement aux apparences initiales, ce n'Ã©tait ni une cyberattaque ni un problÃ¨me rÃ©seau BGP, mais un changement apparemment anodin dans les permissions d'une base de donnÃ©es ClickHouse.

## ğŸ”´ Chronologie de l'Incident

| Heure (UTC) | Ã‰vÃ©nement |
|-------------|-----------|
| **11:05** | DÃ©ploiement du changement de permissions ClickHouse |
| **11:28** | DÃ©but de la panne - PremiÃ¨res erreurs 5xx |
| **11:35** | CrÃ©ation de l'incident call |
| **13:05** | Mise en place de bypasses pour Workers KV et Access |
| **14:30** | RÃ©solution principale - DÃ©ploiement du bon fichier |
| **17:06** | Tous les services restaurÃ©s |

**DurÃ©e totale : ~6 heures**

### Impact

- **Services principaux down** : CDN, WAF, Bot Management
- **Services partiellement affectÃ©s** : Workers KV, Access, Dashboard
- **Taux d'erreur** : Pic massif de codes HTTP 5xx
- **Utilisateurs impactÃ©s** : Millions Ã  travers le monde

---

## ğŸ” Cause Racine : Un Changement de Permissions ClickHouse

### Le SystÃ¨me AffectÃ©

Cloudflare utilise **ClickHouse** pour gÃ©nÃ©rer un fichier de configuration pour son systÃ¨me **Bot Management**. Ce fichier contient des "features" (caractÃ©ristiques) utilisÃ©es par un modÃ¨le de machine learning pour dÃ©tecter les bots.

**Fonctionnement normal :**
```
ClickHouse Query
    â†“
GÃ©nÃ¨re fichier de features (~60 features)
    â†“
DÃ©ploie toutes les 5 minutes sur le rÃ©seau global
    â†“
Bot Management utilise les features pour scorer le trafic
```

### Architecture ClickHouse

```yaml
ClickHouse Cluster:
  - Database: default (tables distribuÃ©es)
  - Database: r0 (tables sous-jacentes par shard)
  
RequÃªtes distribuÃ©es:
  - Via compte systÃ¨me partagÃ©
  - AccÃ¨s implicite Ã  r0 (invisible aux utilisateurs)
```

### Le Changement Fatal

Ã€ **11:05 UTC**, Cloudflare a dÃ©ployÃ© un changement pour **amÃ©liorer la sÃ©curitÃ©** :

**Objectif** : Rendre l'accÃ¨s aux tables `r0` explicite (au lieu d'implicite)

**BÃ©nÃ©fice attendu** : 
- Meilleure gestion des permissions
- Limites par requÃªte plus granulaires
- Meilleure visibilitÃ© pour les utilisateurs

**ProblÃ¨me imprÃ©vu** : Une requÃªte critique n'Ã©tait **pas filtrÃ©e par database** :

```sql
-- RequÃªte utilisÃ©e pour gÃ©nÃ©rer le fichier de features
SELECT name, type
FROM system.columns
WHERE table = 'http_requests_features'
ORDER BY name;
```

**Avant le changement :**
```
Retourne uniquement les colonnes de `default.http_requests_features`
â†’ ~60 features
```

**AprÃ¨s le changement :**
```
Retourne les colonnes de:
  - default.http_requests_features
  - r0.http_requests_features (sur chaque shard)
â†’ Plus de 200 features (duplicatas)
```

---

## ğŸ’¥ La Cascade de Pannes

### 1. Limite de Taille DÃ©passÃ©e

Le proxy Cloudflare (FL2) a une **limite codÃ©e en dur** :

```rust
// Code Rust dans FL2
const MAX_FEATURES: usize = 200;

fn load_bot_features(file: &FeatureFile) -> Result<()> {
    if file.features.len() > MAX_FEATURES {
        return Err("Too many features"); // ğŸ”¥ PANIC ICI
    }
    // ...
}
```

**Pourquoi cette limite ?**
- PrÃ©-allocation mÃ©moire pour performance
- Ã‰viter consommation mÃ©moire non bornÃ©e
- Limite "safe" : 200 >> 60 features normaux

### 2. Panic Non GÃ©rÃ©

```
thread fl2_worker_thread panicked: 
called Result::unwrap() on an Err value
```

**RÃ©sultat** : Le proxy crashe pour chaque requÃªte utilisant Bot Management

### 3. Propagation Intermittente

Le cluster ClickHouse Ã©tait mis Ã  jour **progressivement** :

```
Toutes les 5 minutes :
  - Si requÃªte hit un node MIS Ã€ JOUR â†’ Mauvais fichier (>200 features)
  - Si requÃªte hit un node NON MIS Ã€ JOUR â†’ Bon fichier (~60 features)

RÃ©sultat : SystÃ¨me oscille entre "marche" et "ne marche pas"
```

Cette intermittence a **induit l'Ã©quipe en erreur** : ils ont cru Ã  une attaque DDoS !

---

## ğŸ­ Les Fausses Pistes

### Piste 1 : Attaque DDoS

**SymptÃ´mes trompeurs :**
- Fluctuations rapides de disponibilitÃ©
- Le status page de Cloudflare (hÃ©bergÃ© ailleurs) Ã©tait aussi down (coÃ¯ncidence)
- Ressemble aux rÃ©centes attaques Aisuru (15 Tbps)

**Message interne de l'Ã©quipe :**
```
11:35 - Incident Chat Room
"Could this be a continuation of recent Aisuru DDoS attacks?"
"Status page is down too - coordinated attack?"
```

### Piste 2 : ProblÃ¨me Workers KV

**SymptÃ´me initial** : Workers KV montrait des erreurs Ã©levÃ©es

**Action prise** : Mitigation sur Workers KV, limitation de comptes

**RÃ©alitÃ©** : Workers KV Ã©tait une **victime collatÃ©rale** (dÃ©pend du core proxy)

---

## ğŸ› ï¸ La RÃ©solution

### Ã‰tape 1 : Isolation (13:05)

```python
# Bypass du core proxy pour Workers KV et Access
# â†’ Utiliser l'ancienne version du proxy (FL)

# Impact de FL vs FL2 :
# - FL2 : Panic â†’ 5xx errors
# - FL  : Pas de panic, mais bot score = 0 pour tout le trafic
```

### Ã‰tape 2 : Identification (14:24)

```bash
# L'Ã©quipe identifie la cause :
1. Le fichier Bot Management est trop gros
2. Stopper la gÃ©nÃ©ration automatique
3. Tester un ancien fichier connu bon
```

### Ã‰tape 3 : DÃ©ploiement du Fix (14:30)

```bash
# 1. Stopper propagation du mauvais fichier
stop_bot_feature_generation()

# 2. Injecter manuellement un bon fichier
inject_known_good_file(version="11:00-UTC")

# 3. Forcer restart du core proxy
force_restart_core_proxy()
```

### Ã‰tape 4 : Restauration ComplÃ¨te (17:06)

- RedÃ©marrage de tous les services downstream
- Retour Ã  la normale du trafic
- RÃ©solution du backlog de requÃªtes

---

## ğŸ’¡ LeÃ§ons Techniques

### 1. Toujours Filtrer par Database

**Code problÃ©matique :**
```sql
SELECT name, type
FROM system.columns
WHERE table = 'http_requests_features'  -- âŒ Pas de filtre database
ORDER BY name;
```

**Code correct :**
```sql
SELECT name, type
FROM system.columns
WHERE 
    database = 'default' AND           -- âœ… Filtre explicite
    table = 'http_requests_features'
ORDER BY name;
```

### 2. GÃ©rer les Erreurs Gracefully

**Code fragile (Rust) :**
```rust
let features = load_features(&file).unwrap();  // âŒ Panic si erreur
```

**Code robuste :**
```rust
let features = match load_features(&file) {
    Ok(f) => f,
    Err(e) => {
        log_error!("Failed to load features: {}", e);
        metrics::increment("bot_feature_load_error");
        
        // Fallback sur cache ou ancienne version
        return load_cached_features();
    }
};
```

### 3. Valider les Inputs, MÃªme Internes

**Principe :**
```rust
// Ne JAMAIS assumer qu'un fichier gÃ©nÃ©rÃ© en interne est valide

fn validate_feature_file(file: &FeatureFile) -> Result<()> {
    // VÃ©rifications
    if file.features.len() > MAX_FEATURES {
        return Err("Too many features");
    }
    
    if file.features.len() == 0 {
        return Err("Empty feature file");
    }
    
    // VÃ©rifier duplicates
    if has_duplicates(&file.features) {
        return Err("Duplicate features detected");
    }
    
    Ok(())
}

// Utiliser AVANT de propager
validate_feature_file(&file)?;
propagate_to_network(&file);
```

### 4. Canary Deployments

**Erreur de Cloudflare :**
```
Changement dÃ©ployÃ© graduellement sur le cluster ClickHouse
MAIS fichier propagÃ© instantanÃ©ment sur TOUT le rÃ©seau
```

**Meilleure approche :**
```python
def deploy_feature_file(file):
    # 1. Valider
    if not validate(file):
        raise ValueError("Invalid file")
    
    # 2. Deploy canary (1% du trafic)
    deploy_to_canary_nodes(file, percentage=0.01)
    
    # 3. Monitor 5 minutes
    if error_rate > threshold:
        rollback()
        return
    
    # 4. Deploy progressivement
    for percentage in [10, 25, 50, 100]:
        deploy_to_nodes(file, percentage)
        monitor(duration=300)  # 5 min
```

### 5. Kill Switches Globaux

**Ce que Cloudflare a annoncÃ© :**
```yaml
# Global kill switches pour chaque feature
features:
  bot_management:
    kill_switch: true  # DÃ©sactive instantanÃ©ment sur tout le rÃ©seau
    fallback: "allow_all"  # Comportement par dÃ©faut si dÃ©sactivÃ©
```

---

## ğŸ“Š Impact par Service

| Service | Impact | Cause |
|---------|--------|-------|
| **Core CDN** | 5xx errors | Core proxy panic |
| **Bot Management** | Score = 0 (FL) ou erreur (FL2) | Feature file invalid |
| **Workers KV** | 5xx errors Ã©levÃ©s | DÃ©pend du core proxy |
| **Cloudflare Access** | Auth failures | DÃ©pend du core proxy |
| **Dashboard** | Indisponible (login) | Turnstile down + KV down |
| **Turnstile** | Failed to load | Core proxy down |
| **Email Security** | Perte IP reputation | DÃ©pendance indirecte |

---

## ğŸ¯ Actions Correctives de Cloudflare

### Court Terme

1. âœ… **Hardening de l'ingestion** des fichiers de config (traiter comme input utilisateur)
2. âœ… **Kill switches globaux** pour toutes les features
3. âœ… **Limiter les core dumps** pour Ã©viter saturation CPU
4. âœ… **Revoir tous les failure modes** dans les modules du proxy

### Moyen Terme

- Tests de chaos engineering sur les configurations
- Validation automatique des fichiers avant propagation
- Monitoring de la taille des fichiers de config
- Alertes sur anomalies de mÃ©tadonnÃ©es ClickHouse

### Long Terme

- Architecture plus rÃ©siliente avec fallbacks
- Isolation plus forte entre les modules
- DÃ©couplage des dÃ©pendances critiques

---

## ğŸ’­ RÃ©flexions

### La FragilitÃ© des SystÃ¨mes Complexes

```
Changement de permission "sÃ©curitÃ©" 
    â†’ RequÃªte non filtrÃ©e retourne duplicatas
    â†’ Fichier double de taille
    â†’ DÃ©passe limite codÃ©e en dur
    â†’ Panic non gÃ©rÃ©
    â†’ Core proxy crash
    â†’ 17% du web down
```

**Un seul maillon faible** dans une chaÃ®ne de 6 Ã©tapes.

### L'Importance des Limites

La limite de 200 features Ã©tait lÃ  pour **protÃ©ger** (prÃ©-allocation mÃ©moire).

Mais elle est devenue un **point de dÃ©faillance** car :
- Pas de validation en amont
- Erreur non gÃ©rÃ©e gracefully
- Pas de fallback

**LeÃ§on** : Les limites de sÃ©curitÃ© doivent avoir des mÃ©canismes de dÃ©gradation gracieuse.

### La DifficultÃ© du Diagnostic

L'intermittence (bon fichier / mauvais fichier toutes les 5 min) a fait perdre **3 heures** Ã  l'Ã©quipe.

**LeÃ§on** : Les failures intermittents sont les plus durs Ã  dÃ©bugger.

---

## ğŸ”— Ressources

- [Post-Mortem Officiel Cloudflare](https://blog.cloudflare.com/18-november-2025-outage/)
- [Architecture FL2 Proxy](https://blog.cloudflare.com/20-percent-internet-upgrade/)
- [ClickHouse Documentation](https://clickhouse.com/docs)
- [Rust Error Handling Best Practices](https://doc.rust-lang.org/book/ch09-00-error-handling.html)

---

## ğŸ’¬ Conclusion

Cette panne rappelle que dans les systÃ¨mes distribuÃ©s Ã  grande Ã©chelle :

1. **Aucun changement n'est anodin** - Un changement de permissions a causÃ© 6h de panne
2. **Toujours filtrer explicitement** - Ne jamais assumer qu'une requÃªte retournera ce qu'on attend
3. **GÃ©rer les erreurs gracefully** - Un `unwrap()` peut faire tomber 17% du web
4. **Valider mÃªme l'input interne** - Traiter les configs internes comme des inputs externes
5. **Avoir des kill switches** - Pour dÃ©sactiver rapidement une feature problÃ©matique

**Question pour vous** : Avez-vous des limites codÃ©es en dur dans votre code qui pourraient devenir des points de dÃ©faillance ? ğŸ¤”
